<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-03-24T20:03:29+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Alp Karaagac</title><subtitle>Personal blog and portfolio - AI, ML, NLP and beyond</subtitle><author><name>Alp Karaagac</name></author><entry><title type="html">Starting My Reinforcement Learning in Finance Project</title><link href="http://localhost:4000/projects/rl/finance/rl-finance-project/" rel="alternate" type="text/html" title="Starting My Reinforcement Learning in Finance Project" /><published>2025-03-22T09:44:44+01:00</published><updated>2025-03-22T09:44:44+01:00</updated><id>http://localhost:4000/projects/rl/finance/rl-finance-project</id><content type="html" xml:base="http://localhost:4000/projects/rl/finance/rl-finance-project/"><![CDATA[<p>Welcome to the first post of my <strong>Reinforcement Learning in Finance</strong> project! ğŸ‘‹</p>

<p>This blog will serve as my public notebook â€” a place to document ideas, experiments, results, mistakes, breakthroughs, and everything in between as I try to answer this core question:</p>

<blockquote>
  <p><em>Can reinforcement learning agents learn to make intelligent decisions in dynamic, noisy financial markets?</em></p>
</blockquote>

<hr />

<h3 id="-why-rl-in-finance">ğŸ’¡ Why RL in Finance?</h3>

<p>Markets are complex, uncertain, and ever-changing â€” which makes them a fascinating environment for reinforcement learning. The idea of training agents that can <strong>learn to trade</strong>, <strong>adapt to new patterns</strong>, or even <strong>discover strategies</strong> is both exciting and challenging.</p>

<p>That said, itâ€™s also messy, data-hungry, and filled with edge cases. Which is exactly why Iâ€™m documenting everything here.</p>

<hr />

<h3 id="-what-im-planning-to-explore">ğŸ”¬ What Iâ€™m Planning To Explore</h3>

<p>Some of the topics Iâ€™ll cover along the way:</p>

<ul>
  <li>âœ… Environment design for market simulation</li>
  <li>âœ… Reward shaping and agent feedback</li>
  <li>âœ… Deep RL algorithms (PPO, DQN, A2C, etc.)</li>
  <li>âœ… Portfolio-level decision making</li>
  <li>âœ… Common pitfalls (overfitting, hindsight bias)</li>
  <li>âœ… Evaluation metrics that actually mean something</li>
</ul>

<hr />

<h3 id="-tech-stack">ğŸ§ª Tech Stack</h3>

<ul>
  <li><strong>Frameworks</strong>: PyTorch, OpenAI Gym, stable-baselines3</li>
  <li><strong>Data</strong>: Yahoo Finance, simulated market data</li>
  <li><strong>Extras</strong>: Pandas, NumPy, Matplotlib, wandb (maybe)</li>
</ul>

<hr />

<h3 id="ï¸-what-to-expect-here">âœï¸ What to Expect Here</h3>

<ul>
  <li>Regular updates as I experiment and build</li>
  <li>Short blog-style deep dives into specific subtopics</li>
  <li>Honest reflections on whatâ€™s working (and whatâ€™s totally not)</li>
</ul>

<p>This project is a learning journey â€” so the goal isnâ€™t just to make something that â€œworksâ€, but to <strong>understand the process</strong>, <strong>ask the right questions</strong>, and <strong>sharpen my thinking</strong> around AI in real-world settings.</p>

<hr />

<p>Thanks for following along ğŸ™Œ<br />
More updates soon. Next post: defining the environment and agent setup!</p>]]></content><author><name>Alp Karaagac</name></author><category term="projects" /><category term="RL" /><category term="finance" /><category term="reinforcement-learning" /><category term="deep-rl" /><category term="trading" /><category term="machine-learning" /><summary type="html"><![CDATA[Welcome to the first post of my Reinforcement Learning in Finance project! ğŸ‘‹]]></summary></entry></feed>